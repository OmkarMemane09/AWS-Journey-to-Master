# ☁️ Amazon Simple Storage Service (S3)
Amazon S3 to store, manage, analyze, and protect any amount of data for virtually any use case, such as data lakes, cloud-native applications, and mobile apps.


## 📖 Introduction
**Amazon S3 (Simple Storage Service)** is an **object storage service** that offers:
- Industry-leading **scalability, durability, and security**
- Storage for **any amount of data** from **anywhere**
- Support for multiple use cases like:
  - Data lakes
  - Cloud-native applications
  - Mobile apps
  - Backup & archival

S3 stores data as **objects** inside **buckets**.

---

## 🪣 Buckets in S3
- Buckets must have a **globally unique name** (across all regions & accounts).
- Buckets are defined at a **region level**.
- S3 looks like a global service, but buckets exist in **specific regions**.

### ✅ Naming Conventions
| Rule | Description |
|------|-------------|
| 🔡 Lowercase only | No uppercase letters allowed |
| ❌ No underscores | Use `-` instead |
| 🔢 Length | 3–63 characters |
| 🚫 Not IP | Cannot look like an IP address (`192.168.0.1`) |
| 🅰️ Start | Must start with a lowercase letter or number |
| 🚫 Prefix | Cannot start with `xn--` |
| 🚫 Suffix | Cannot end with `-s3alias` |

---

# 🌐 Deploying a Static Website on AWS S3

Amazon S3 allows you to **host a static website** (HTML, CSS, JS) directly from a bucket.  

---

## 🚀 Steps to Deploy

### **Step 1: Create a Bucket**
- Go to the **S3 service** in the AWS console.
- Click **Create Bucket**.
- ✅ Ensure:
  - Unique bucket name (e.g., `my-website-demo`).
  - **General Purpose** selected.
  - Choose a region close to users.
- Leave defaults → **Create bucket**.

---

### **Step 2: Upload Website Files**
- Open your bucket → **Upload**.
- Drag & drop **all website files** (HTML, CSS, JS, images).  
⚠️ *Do not upload the entire folder — only the files inside.*

---

### **Step 3: Enable Static Website Hosting**
- Go to **Properties** tab.
- Scroll to **Static website hosting → Edit**.
- Enable hosting:
  - **Index document** → `index.html`
  - *(Optional)* Error document → `error.html`
- Save changes.

---

### **Step 4: Configure Permissions**
1. **Block Public Access**  
   - Go to **Permissions → Block public access**.  
   - 🔓 Uncheck *Block all public access*.  
   - Confirm.

2. **Object Ownership**  
   - Set **ACLs enabled**.  
   - Choose **Bucket owner preferred**.

3. **Access Control List (ACL)**  
   - For **Everyone (public access)** → grant:  
     - ✅ Read  
     - ✅ List  

---

### **Step 5: Make Objects Public**
- Go to **Objects** tab.
- Select all files → **Actions → Make public using ACL**.
- Confirm.

---

### **Step 6: Access the Website**
- Go to **Properties → Static website hosting**.
- Copy the **Bucket website endpoint URL**:  
---
## ❓ Is S3 a global service but bucket a regional service?

### ✅ Answer: Yes  

**Reason:**  
- **S3 is a Global Service**  
  - It provides a **single global namespace** → bucket names must be unique worldwide.  
  - Accessible from any region through the same AWS console and APIs.  

- **Bucket is a Regional Resource**  
  - When creating a bucket, you must choose a **specific AWS region** (e.g., `ap-south-1`).  
  - Data inside the bucket is physically stored and replicated **only within that region’s Availability Zones**.  
  - Bucket endpoints are **region-specific** (e.g., `mybucket.s3.ap-south-1.amazonaws.com`).  

👉 **In short:**  
S3 is global, but each bucket and its data live in a specific AWS region.

---
## 🪣 General Purpose vs Directory Bucket

| Feature | General Purpose Bucket | Directory Bucket |
|---------|------------------------|------------------|
| 📍 Scope | Regional (data stored in one AWS region) | Zonal (data stored in one Availability Zone) |
| 🌐 Use Case | Standard object storage for most workloads (websites, backups, apps) | Low-latency workloads that need single-AZ access |
| 🔄 Durability | Data replicated across multiple AZs in a region | Data stored in one AZ only (lower durability) |
| 💰 Cost | Slightly higher (multi-AZ replication) | Lower cost (single-AZ storage) |
| 🌟 Availability | High (multi-AZ) | Limited (single AZ — less resilient) |

---
## 📊 Comparison: EBS vs EFS vs S3

| **Features**        | **Amazon S3** (Object Storage) | **Amazon EBS** (Block Storage) | **Amazon EFS** (File Storage) |
|----------------------|--------------------------------|--------------------------------|--------------------------------|
| **Type of Storage**  | Object storage | Block storage | File storage |
| **Scalability**      | Unlimited scalability | Manual scaling (increase/decrease volume size) | Unlimited scalability |
| **Reliability**      | Redundant across multiple AZs | Stored in a single AZ | Redundant across multiple AZs |
| **Availability**     | Up to 99.99% (Standard) | Guaranteed uptime 99.99% | No formal SLA |
| **Security**         | Encryption at rest & in transit | Encryption at rest & in transit | Encryption at rest & in transit |
| **Backup & Restore** | Cross-region replication & versioning | Snapshots (automated every 15 mins) | Replication supported (EFS to EFS) |
| **Performance**      | Slower compared to EBS & EFS | Fastest (higher IOPS & throughput) | Faster than S3, slower than EBS |
| **Accessibility**    | Public & private access | Accessible only via attached EC2 | Shared access across multiple EC2 & on-premises |
| **Interface**        | Web-based interface | File system interface | Web + file system interface |
| **Pricing Model**    | Pay-as-you-go | Pay for provisioned capacity | Pay-as-you-go |
| **Use Cases**        | Big data, backups, media, archives, web hosting | Boot volumes, databases, ETL workloads | Media, analytics, backups, content management, shared home directories |

  # Amazon S3 Storage Classes

Amazon S3 provides different storage classes to optimize **cost, durability, and access speed** based on your data needs.

---

## 1. S3 Standard
- **Durability & Availability:** 99.999999999% (11 nines) durability, high availability.
- **Use Case:** Frequently accessed data.
- **Features:** Low latency, high throughput.

---

## 2. S3 Intelligent-Tiering
- **Durability & Availability:** Same as Standard.
- **Use Case:** Data with **unknown or changing access patterns**.
- **Features:** Automatically moves objects between **frequent and infrequent access tiers** to save costs.

---

## 3. S3 Standard-IA (Infrequent Access)
- **Durability & Availability:** High durability, lower availability than Standard.
- **Use Case:** Data accessed less frequently but requires rapid access.
- **Cost:** Lower storage cost, charges for retrieval.

---

## 4. S3 One Zone-IA
- **Durability:** Data stored in **single availability zone**.
- **Use Case:** Non-critical, infrequently accessed data.
- **Cost:** Lower than Standard-IA.

---

## 5. S3 Glacier
- **Durability:** 11 nines.
- **Use Case:** Archival storage; data rarely accessed.
- **Retrieval:** Minutes to hours depending on retrieval option.
- **Cost:** Very low storage cost.

---

## 6. S3 Glacier Deep Archive
- **Durability:** 11 nines.
- **Use Case:** Long-term archive, compliance data, rarely accessed.
- **Retrieval:** Within 12 hours.
- **Cost:** Lowest storage cost among all classes.

---
<img width="1824" height="1528" alt="S3-Storage-Classes-Performance" src="https://github.com/user-attachments/assets/1e858d1d-b4d8-4e27-8763-b8b4b5b87eb3" />


# Amazon S3 Replication Rules

## 1. What is S3 Replication?
- S3 Replication allows you to **automatically copy objects** from one S3 bucket to another.
- Can be **within the same AWS region (CRR – Cross-Region Replication)** or **across regions (CRR)**.
- Helps with **data redundancy, compliance, and disaster recovery**.

---

## 2. Types of Replication
| Type                          | Description |
|-------------------------------|-------------|
| **Same-Region Replication (SRR)** | Replicates objects within the same AWS region to another bucket. Useful for analytics or compliance. |
| **Cross-Region Replication (CRR)** | Replicates objects to a bucket in another AWS region. Useful for disaster recovery and latency reduction. |

---

## 3. Pre-requisites for Replication
- Source and destination buckets must exist.
- Enable **versioning** on both source and destination buckets.
- Appropriate **IAM role** with permissions to replicate objects.
- Both buckets must have compatible **storage classes**.

---

## 4. Steps to Create a Replication Rule
1. Navigate to **S3 → Select Source Bucket → Management → Replication rules → Create replication rule**.
2. Enter a **rule name**.
3. Choose **scope**:
   - **All objects** or **a subset of objects** using prefix or tags.
4. Select **destination bucket**.
5. Choose **replication options**:
   - Change storage class (optional)
   - Replicate delete markers (optional)
   - Replicate existing objects (optional)
6. Assign or create an **IAM role** for replication.
7. Review and **create the replication rule**.

---

## 5. Best Practices
- Use **Cross-Region Replication** for disaster recovery.
- Enable **replication metrics and notifications** for monitoring.
- Use **prefixes or tags** to replicate only required objects.
- Ensure **versioning** is enabled on both source and destination buckets.
- Monitor **replication status** in the S3 console.

---
## 🔁 AWS S3 Replication (CRR & SRR)

Replication in Amazon S3 allows you to **automatically copy objects** between buckets.  
There are two types:  

- **CRR (Cross-Region Replication):** Replication across different AWS regions.  
- **SRR (Same-Region Replication):** Replication within the same region.  

### ⚙️ Key Requirements
- **Versioning** must be enabled on **source & destination** buckets.  
- Buckets can belong to **different AWS accounts**.  
- Replication is **asynchronous**.  
- Requires **IAM role with proper S3 permissions**.  

### 📌 Use Cases
- **CRR:**  
  - Compliance  
  - Lower latency for global users  
  - Replication across AWS accounts  

- **SRR:**  
  - Log aggregation  
  - Sync between production & test environments  
  - Real-time replication within the same region  

### 📝 Important Notes
- After enabling replication, **only new objects** are replicated.  
- Existing objects can be replicated using **S3 Batch Replication** (including failed ones).  
- **Delete markers** can be replicated, but deletions with a **version ID** are **not** replicated.  
- ❌ **No replication chaining:**  
  - If Bucket1 → Bucket2 and Bucket2 → Bucket3  
  - Objects from Bucket1 will **not** automatically replicate to Bucket3.  


---

# Amazon S3 Bucket Properties

## 1. Versioning
- Keeps **multiple versions** of objects in the bucket.
- Helps **recover deleted or overwritten files**.
- Options:
  - **Enabled**
  - **Suspended**

---

## 2. Encryption
- Protects data **at rest**.
- Options:
  - **SSE-S3**: Server-side encryption with S3 managed keys.
  - **SSE-KMS**: Server-side encryption with AWS KMS managed keys.
  - **SSE-C**: Server-side encryption with customer-provided keys.

---

## 3. Logging
- Enable **server access logging** to track requests to the bucket.
- Logs can be stored in another S3 bucket.

---

## 4. Object Lock
- Helps **prevent accidental deletion or modification**.
- Useful for **compliance and regulatory requirements**.
- Options:
  - **Governance mode**: Users with special permissions can override.
  - **Compliance mode**: Cannot be overwritten or deleted.

---

## 5. Tags
- Key-value pairs to **organize, track, and manage costs**.
- Example: `Environment=Production`, `Project=DevOps`.

---

## 6. Events
- Trigger actions on bucket activity:
  - Lambda functions
  - SQS queues
  - SNS topics

---

## 7. Transfer Acceleration
- Speeds up **uploads and downloads** using AWS edge locations.
- Useful for **globally distributed users**.

---

## 8. Storage Class
- Default storage class for new objects:
  - **Standard**
  - **Intelligent-Tiering**
  - **Standard-IA**
  - **One Zone-IA**
  - **Glacier / Deep Archive**

---

## 9. Lifecycle Rules
- Automatically **transition objects to cheaper storage** or **delete them** after a period.
- Helps in **cost optimization** and **data management**.

---

## 10. Permissions
- **Bucket policy**: JSON-based access control.
- **Access Control List (ACL)**: Grant read/write access to specific users.
- **IAM policies**: Control access for users and roles.

---

# S3 Advanced Features

## 1. Versioning
- **Purpose:** Keep multiple versions of an object to protect against accidental deletion or overwrites.  
- **Enable Versioning:**
  1. Go to **S3 → Select Bucket → Properties**.
  2. Click **Versioning → Enable**.
- **Use Cases:**
  - Recover deleted objects.
  - Restore previous object versions.
- **Best Practices:**
  - Enable versioning for **critical data**.
  - Combine with **Lifecycle rules** to manage old versions and reduce costs.

---

## 2. Static Website Hosting
- **Purpose:** Host static websites (HTML, CSS, JS) directly from S3.  
- **Enable Static Website Hosting:**
  1. Go to **S3 → Select Bucket → Properties → Static website hosting**.
  2. Choose **Enable**.
  3. Specify:
     - **Index document** (e.g., `index.html`)
     - **Error document** (optional, e.g., `error.html`)
  4. Save changes.
- **Access Website:**
  - AWS provides a **bucket endpoint URL** to access the site.  
- **Use Cases:**
  - Hosting landing pages, documentation, or static apps.
- **Best Practices:**
  - Enable **CloudFront** for faster delivery and HTTPS support.
  - Keep public access only if required.

---

## 3. Server Access Logging
- **Purpose:** Track requests made to the bucket for **audit and security purposes**.  
- **Enable Server Access Logging:**
  1. Go to **S3 → Select Bucket → Properties → Server access logging**.
  2. Enable logging and select a **target bucket** to store logs.
  3. Save changes.
- **Use Cases:**
  - Monitor who accessed objects and when.
  - Detect unauthorized access.
  - Analyze usage patterns.
- **Best Practices:**
  - Use a **separate bucket** for logs.
  - Apply **lifecycle rules** to manage log retention and reduce storage costs.

 ## 🔄 AWS S3 Lifecycle Rules

Amazon S3 Lifecycle rules help you **automate object management** by defining policies that transition objects to cheaper storage classes or expire them after a specified time.  
This improves **cost optimization** and **data management**.

---

### 🔀 Transition Actions
Automatically move objects between storage classes after a set time:
- Move to **Standard-IA (Infrequent Access)** → after **60 days** of creation.  
- Move to **Glacier** → after **6 months** for archival storage.  

---

### ❌ Expiration Actions
Automatically delete objects after a defined time:
- Delete **access log files** → after **365 days**.  
- Delete **old versions** of files (when versioning is enabled).  
- Delete **incomplete multipart uploads**.  

---

### 🎯 Rule Targeting
Lifecycle rules can be applied to:
- **Specific prefixes** → Example: `logs/` or `backups/`.  
- **Objects with specific tags** → Example: `Environment=Dev` or `Project=App1`.  

---

<img width="700" height="297" alt="image" src="https://github.com/user-attachments/assets/1256a710-6f9e-4581-98dd-96cdbbf5199d" />


